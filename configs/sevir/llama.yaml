sevir: &sevir
  type: sevir
  input_length: &input_length 13 
  pred_length: &pred_length 12
  total_length: &total_length 25
  base_freq: 5min
  data_dir: radar:s3://weather_radar_datasets/sevir

dataset:
  train:
    <<: *sevir

  valid:
    <<: *sevir

sampler:
  type: TrainingSampler

dataloader:
  num_workers: 16 
  pin_memory: False
  prefetch_factor: 2
  persistent_workers: True

trainer:
  batch_size: 16 # to check
  valid_batch_size: 24
  max_epoch: &max_epoch 1
  max_step: 55000

model:
  type: non_ar_model
  params:
    sub_model:
      llama:
        hidden_size: 384
        intermediate_size: 1152
        num_hidden_layers: 12
        num_attention_heads: 8
        _flash_attn_2_enabled: True
        img_size: [384,384]
        patch_size: [4,4] 
        patch_stride: [4,4] 
        in_chans: 13
        out_chans: 12
        gradient_checkpointing: False

    save_best: &loss_type MSE
    use_ceph: True
    ceph_checkpoint_path: "mpas:s3://sevir/checkpoint"
    metrics_type: SEVIRSkillScore
    data_type: fp32

    visualizer:
      visualizer_type: sevir_visualizer
      visualizer_step: 8000

    optimizer:
      llama:
        type: AdamW
        params:
          lr: 0.001
          betas: [0.9, 0.999]
          weight_decay: 0.00001
          # eps: 0.000001

    lr_scheduler:
      llama:
        by_step: True
        sched: cosine
        epochs: *max_epoch
        min_lr: 0.
        warmup_lr: 0.
        warmup_epochs: 0.2
        lr_noise: 
        cooldown_epochs: 0

    extra_params:
      loss_type: MSELoss
      enabled_amp: False
      log_step: 20
      z_score_delta: False

    wandb:
      project_name: sevir